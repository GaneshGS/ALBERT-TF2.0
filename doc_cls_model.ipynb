{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doc_cls_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwQaluydweFa+Ij1LOW6Wb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaneshGS/ALBERT-TF2.0/blob/master/doc_cls_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNnAioo3qFtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "677cb872-109e-46e4-bd07-d14e2730c395"
      },
      "source": [
        "def doc_cls_model():\n",
        "  from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "  import tensorflow as tf\n",
        "  tf.enable_eager_execution()\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from numpy import genfromtxt  \n",
        "  import io\n",
        "  import os\n",
        "  import tarfile\n",
        "  from google.colab import drive\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "  from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSI9sWtHqZPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def extract_process_data():\n",
        "\n",
        "    drive.mount('/content/drive/') \n",
        "    %cd '/content/drive/My Drive'\n",
        "    !tar -xvf yahoo_answers_csv.tar.gz\n",
        "    %cd '/content/drive/My Drive'\n",
        "    column_defaults = [tf.int32, tf.constant('', tf.string), tf.constant('', tf.string), tf.constant('', tf.string)]\n",
        "    column_names = ['content', 'qtype', 'qcontent', 'answer']\n",
        "    feature_names = column_names[:0]\n",
        "    label_name = column_names[0]\n",
        "    batch_size = 1\n",
        "\n",
        "    train_data = tf.data.experimental.make_csv_dataset(\"train.csv\",\n",
        "                                                       batch_size,\n",
        "                                                       column_names,\n",
        "                                                       column_defaults,\n",
        "                                                       label_name,\n",
        "                                                       field_delim = ',',\n",
        "                                                       num_epochs=1)\n",
        "    test_data = tf.data.experimental.make_csv_dataset(\"test.csv\",\n",
        "                                                      batch_size,\n",
        "                                                      column_names,\n",
        "                                                      column_defaults,\n",
        "                                                      label_name,\n",
        "                                                      field_delim = ',',\n",
        "                                                      num_epochs=1)  \n",
        "    features, labels = next(iter(train_data))\n",
        "\n",
        "    def features_vector(features, labels):\n",
        "      features = tf.stack(list(features.values()), axis=1)\n",
        "      return features, labels\n",
        "\n",
        "    train_data = train_data.map(features_vector)\n",
        "    test_data = test_data.map(features_vector)\n",
        "\n",
        "    train_sentences = []\n",
        "    train_labels = []\n",
        "    test_sentences = []\n",
        "    test_labels = []\n",
        "\n",
        "    for i,j in train_data:\n",
        "      train_sentences.append(str(i.numpy()))\n",
        "      train_labels.append(int(j.numpy()))\n",
        "\n",
        "    for i,j in test_data:\n",
        "      test_sentences.append(str(i.numpy()))\n",
        "      test_labels.append(int(j.numpy()))\n",
        "  \n",
        "    for i in train_labels:\n",
        "      if i == 0:\n",
        "        print(i)\n",
        "      else:\n",
        "        exit\n",
        "\n",
        "    for i in test_labels:\n",
        "      if i == 0:\n",
        "        print(i)\n",
        "      else:\n",
        "        exit\n",
        "      \n",
        "    train_labels_f = []\n",
        "    test_labels_f = []\n",
        "\n",
        "    for i in train_labels:\n",
        "      train_labels_f.append(i-1)\n",
        "\n",
        "    for i in test_labels:\n",
        "      test_labels_f.append(i-1)\n",
        "  \n",
        "    train_labels_fn = np.array(train_labels_f)\n",
        "    test_labels_fn = np.array(test_labels_f)\n",
        "\n",
        "    return train_sentences, test_sentences, train_labels_f, test_labels_f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4k2x5I5yC3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def Tokenization_extraction():\n",
        "    vocab_size = 50000\n",
        "    embedding_dim = 128\n",
        "    max_length = 200\n",
        "    trunc_type='post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "\n",
        "    tokenizer = Tokenizer(num_words =vocab_size, oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "    train_padded = pad_sequences(train_sequences,maxlen=max_length, truncating=trunc_type, padding='post')\n",
        "\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "    test_padded = pad_sequences(test_sequences,maxlen=max_length, truncating=trunc_type, padding='post')\n",
        "\n",
        "    train_sent_par = train_padded[:1050000]\n",
        "    train_label_par = train_labels_fn[:1050000]\n",
        "\n",
        "    validation_sentence = train_padded[1050000:]\n",
        "    validation_label = train_labels_fn[1050000:]\n",
        "\n",
        "    return train_sent_par,train_label_par, validation_sentence, validation_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_3E_V5CyJER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def doc_cls_model():\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length, mask_zero=True),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),               \n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy']) \n",
        "    output  = model.fit(train_sent_par,\n",
        "                        train_label_par,\n",
        "                        epochs = 10,\n",
        "                        batch_size = 512,\n",
        "                        validation_data=(validation_sentence, validation_label),\n",
        "                        verbose=1\n",
        "                        )\n",
        "    results = model.evaluate(test_padded, test_labels_fn)\n",
        "    return model, output, results  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLfTYu1E8y-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model = doc_cls_model()\n",
        "  model.summary()\n",
        "  model.save('doc_cls_model.h5')\n",
        "  return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfJ5_DrC8cmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = keras.models.load_model('doc_cls_model.h5')\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7MggQ3EQ_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}